{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 39763,
          "databundleVersionId": 11756775,
          "sourceType": "competition"
        },
        {
          "sourceId": 11569755,
          "sourceType": "datasetVersion",
          "datasetId": 7253661
        },
        {
          "sourceId": 12076976,
          "sourceType": "datasetVersion",
          "datasetId": 7602253
        },
        {
          "sourceId": 12076984,
          "sourceType": "datasetVersion",
          "datasetId": 7602260,
          "isSourceIdPinned": true
        },
        {
          "sourceId": 12076998,
          "sourceType": "datasetVersion",
          "datasetId": 7602270
        },
        {
          "sourceId": 12077004,
          "sourceType": "datasetVersion",
          "datasetId": 7602275
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karin-kaito/FWI_202506/blob/main/ensemble_csv_with_public_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "# kagglehub.login()\n"
      ],
      "metadata": {
        "id": "dByIo8x-H8Ok"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 2
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "# waveform_inversion_path = kagglehub.competition_download('waveform-inversion')\n",
        "# egortrushin_open_wfi_test_path = kagglehub.dataset_download('egortrushin/open-wfi-test')\n",
        "# atom1231_caformer_28_2_path = kagglehub.dataset_download('atom1231/caformer-28-2')\n",
        "atom1231_caformrt_28_8_path = kagglehub.dataset_download('atom1231/caformrt-28-8')\n",
        "atom1231_convnext0small_33_2_path = kagglehub.dataset_download('atom1231/convnext0small-33-2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "n1fPKgWMH8Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfa947e-66db-4074-d9ea-304662f5b65b"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/atom1231/caformrt-28-8?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 382M/382M [00:01<00:00, 218MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/atom1231/convnext0small-33-2?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 475M/475M [00:03<00:00, 161MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "atom1231_caformrt_28_8_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ygBaioLVcOg4",
        "outputId": "53da182b-bacf-49ab-dcd3-26d9b40289b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/datasets/atom1231/caformrt-28-8/versions/1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZubLbHJcYWt",
        "outputId": "9cb0bbf3-1760-4f6b-dbd8-60caf8f8c3d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 359.2 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find files to load and create Dataset"
      ],
      "metadata": {
        "id": "vR9LSV2AH8Or"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 日本語へ変更済"
      ],
      "metadata": {
        "id": "tBc9VYnPJClD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S37ypVjEdxba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VL3YGuJkdw0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def ensemble_submissions(file_paths, output_dir='.', weights=None):\n",
        "    \"\"\"\n",
        "    複数の submission CSV ファイルを統合し、必要に応じて加重平均を計算します。\n",
        "\n",
        "    Args:\n",
        "        file_paths (list): すべての submission.csv ファイルのパスを含むリスト。\n",
        "        output_dir (str): 結果ファイルが保存されるディレクトリ。\n",
        "        weights (list, optional): file_paths に対応する重みのリスト。\n",
        "                                  None の場合、単純平均を計算します。デフォルトは None です。\n",
        "    \"\"\"\n",
        "    if not file_paths:\n",
        "        print(\"エラー：ファイルパスリストが空です。\")\n",
        "        return\n",
        "\n",
        "    # --- 新規追加：重み検証 ---\n",
        "    if weights is not None:\n",
        "        if len(weights) != len(file_paths):\n",
        "            print(f\"エラー：重みリストの長さ ({len(weights)}) がファイルリストの長さ ({len(file_paths)}) と一致しません。\")\n",
        "            return\n",
        "        print(f\"加重統合を開始します。使用する重みは: {weights}\")\n",
        "    else:\n",
        "        print(f\"単純平均統合を開始します（重みは提供されていません）。\")\n",
        "\n",
        "    # --- ステップ 1: すべての CSV ファイルを読み込み、'oid_ypos' をインデックスに設定します ---\n",
        "    try:\n",
        "        print(\"CSV ファイルを読み込んでいます...\")\n",
        "        dataframes = [pd.read_csv(f, index_col='oid_ypos') for f in file_paths]\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"エラー：ファイルが見つかりません -> {e}。ファイルパスが正しいか確認してください。\")\n",
        "        return\n",
        "    except KeyError:\n",
        "        print(\"エラー：いずれかのファイルに 'oid_ypos' 列が見つかりません。すべての CSV にこの列があることを確認してください。\")\n",
        "        return\n",
        "\n",
        "    # --- ステップ 2: データの位置合わせとスタック ---\n",
        "    print(\"データを位置合わせしています...\")\n",
        "    master_index = dataframes[0].index\n",
        "    master_columns = dataframes[0].columns\n",
        "    aligned_data = [df.reindex(master_index).values for df in dataframes]\n",
        "    data_array = np.stack(aligned_data, axis=0).transpose(1, 2, 0)\n",
        "    print(\"データスタックが完了しました。配列の次元 (行数, 列数, ファイル数):\", data_array.shape)\n",
        "\n",
        "    # --- ステップ 3: 平均値 (加重または単純) と中央値を計算します ---\n",
        "\n",
        "    # 平均値を計算\n",
        "    if weights is not None:\n",
        "        print(\"加重平均値を計算しています...\")\n",
        "        # np.average を使用して加重計算\n",
        "        mean_data = np.average(data_array, axis=2, weights=weights)\n",
        "        mean_output_filename = 'ensemble_weighted_mean.csv'\n",
        "    else:\n",
        "        print(\"単純平均値を計算しています...\")\n",
        "        mean_data = np.mean(data_array, axis=2)\n",
        "        mean_output_filename = 'ensemble_mean.csv'\n",
        "\n",
        "    # 計算中央值 (中央値に加重の概念はありません)\n",
        "    print(\"中央値を計算しています...\")\n",
        "    median_data = np.median(data_array, axis=2)\n",
        "\n",
        "    # --- ステップ 4: 結果 DataFrame を作成し、CSV ファイルとして保存します ---\n",
        "    # 平均値の結果\n",
        "    df_mean = pd.DataFrame(mean_data, index=master_index, columns=master_columns)\n",
        "    mean_output_path = os.path.join(output_dir, 'submission.csv')\n",
        "    df_mean.to_csv(mean_output_path)\n",
        "    print(f\"平均値統合結果が以下に保存されました: {mean_output_path}\")\n",
        "\n",
        "    # # 中央値の結果\n",
        "    # df_median = pd.DataFrame(median_data, index=master_index, columns=master_columns)\n",
        "    # median_output_path = os.path.join(output_dir, 'ensemble_median.csv')\n",
        "    # df_median.to_csv(median_output_path)\n",
        "    # print(f\"中央値統合結果が以下に保存されました: {median_output_path}\")\n",
        "\n",
        "# 2. すべての submission.csv ファイルのパスリストを定義します。\n",
        "#    以下のリストをあなたのファイルパスに置き換えてください。\n",
        "submission_files = [\n",
        "    \"/root/.cache/kagglehub/datasets/atom1231/caformrt-28-8/versions/1/submission.csv\",\n",
        "    \"/root/.cache/kagglehub/datasets/atom1231/convnext0small-33-2/versions/1/submission.csv\",\n",
        "  #\"/kaggle/input/convnext-base-29-6/submission.csv\" # このパスも同様に修正が必要です。\n",
        "]\n",
        "\n",
        "file_weights = [0.8, 0.2]\n",
        "# 3. 統合関数を実行します。\n",
        "ensemble_submissions(submission_files, weights=file_weights)\n",
        "#単純平均\n",
        "#ensemble_submissions(submission_files)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1F43OHCeI9NL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce0ca9e-ae23-422f-ea21-83133d2d5f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "加重統合を開始します。使用する重みは: [0.8, 0.2]\n",
            "CSV ファイルを読み込んでいます...\n",
            "データを位置合わせしています...\n",
            "データスタックが完了しました。配列の次元 (行数, 列数, ファイル数): (4607260, 35, 2)\n",
            "加重平均値を計算しています...\n",
            "中央値を計算しています...\n",
            "平均値統合結果が以下に保存されました: ./submission.csv\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGRb-qJfgzXD",
        "outputId": "a48165fb-f459-46ad-adb7-d2319002d56b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj_YfrG2g64X",
        "outputId": "70b2e03a-aa14-410c-aa4d-c04c5c944af6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrSNcWEog8fg",
        "outputId": "e663e1c5-0298-4f16-f336-96d359b73197"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2318808\n",
            "drwxr-xr-x 1 root root       4096 Jun  8 07:42 .\n",
            "drwxr-xr-x 1 root root       4096 Jun  8 07:38 ..\n",
            "drwxr-xr-x 4 root root       4096 Jun  5 13:29 .config\n",
            "drwxr-xr-x 1 root root       4096 Jun  5 13:30 sample_data\n",
            "-rw-r--r-- 1 root root 2374437553 Jun  8 07:45 submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4iKaSisg-Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75f22104",
        "outputId": "086fab09-75b3-47b3-91ff-e998077d340b"
      },
      "source": [
        "import os\n",
        "\n",
        "# Check the files in the specified directory\n",
        "directory_path = '/kaggle/input/caformrt-28-8/'\n",
        "if os.path.exists(directory_path):\n",
        "    print(f\"Files in {directory_path}:\")\n",
        "    for filename in os.listdir(directory_path):\n",
        "        print(filename)\n",
        "else:\n",
        "    print(f\"Directory not found: {directory_path}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory not found: /kaggle/input/caformrt-28-8/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e62bd28",
        "outputId": "1c9bf911-97ed-446d-d143-83b8b112f6bc"
      },
      "source": [
        "import os\n",
        "\n",
        "# List all items in the /kaggle/input directory\n",
        "input_directory = '/kaggle/input/'\n",
        "if os.path.exists(input_directory):\n",
        "    print(f\"Contents of {input_directory}:\")\n",
        "    for item_name in os.listdir(input_directory):\n",
        "        print(item_name)\n",
        "else:\n",
        "    print(f\"Directory not found: {input_directory}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /kaggle/input/:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3300869b",
        "outputId": "0dd011c2-a1f3-41f0-db88-5248bc49c67e"
      },
      "source": [
        "import os\n",
        "\n",
        "# List all items in the /kaggle/input directory\n",
        "input_directory = '/kaggle/input/'\n",
        "if os.path.exists(input_directory):\n",
        "    print(f\"Contents of {input_directory}:\")\n",
        "    for item_name in os.listdir(input_directory):\n",
        "        print(item_name)\n",
        "else:\n",
        "    print(f\"Directory not found: {input_directory}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /kaggle/input/:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "# def ensemble_submissions(file_paths, output_dir='.', weights=None):\n",
        "#     \"\"\"\n",
        "#     將多個 submission CSV 檔案進行整合，可選擇計算加權平均。\n",
        "\n",
        "#     Args:\n",
        "#         file_paths (list): 一個包含所有 submission.csv 檔案路徑的列表。\n",
        "#         output_dir (str): 輸出結果檔案的儲存目錄。\n",
        "#         weights (list, optional): 一個與 file_paths 對應的權重列表。\n",
        "#                                   若為 None，則計算簡單平均。預設為 None。\n",
        "#     \"\"\"\n",
        "#     if not file_paths:\n",
        "#         print(\"錯誤：檔案路徑列表是空的。\")\n",
        "#         return\n",
        "\n",
        "#     # --- 新增：權重驗證 ---\n",
        "#     if weights is not None:\n",
        "#         if len(weights) != len(file_paths):\n",
        "#             print(f\"錯誤：權重列表的長度 ({len(weights)}) 與檔案列表的長度 ({len(file_paths)}) 不符。\")\n",
        "#             return\n",
        "#         print(f\"開始進行加權整合，使用的權重為: {weights}\")\n",
        "#     else:\n",
        "#         print(f\"開始進行簡單平均整合（未提供權重）。\")\n",
        "\n",
        "#     # --- 步驟 1: 讀取所有 CSV 檔案，並將 'oid_ypos' 設為索引 ---\n",
        "#     try:\n",
        "#         print(\"正在讀取 CSV 檔案...\")\n",
        "#         dataframes = [pd.read_csv(f, index_col='oid_ypos') for f in file_paths]\n",
        "#     except FileNotFoundError as e:\n",
        "#         print(f\"錯誤：找不到檔案 -> {e}。請檢查您的檔案路徑是否正確。\")\n",
        "#         return\n",
        "#     except KeyError:\n",
        "#         print(\"錯誤：某個檔案中找不到 'oid_ypos' 欄位。請確保所有 CSV 都有此欄位。\")\n",
        "#         return\n",
        "\n",
        "#     # --- 步驟 2: 資料對齊與堆疊 ---\n",
        "#     print(\"正在對齊資料...\")\n",
        "#     master_index = dataframes[0].index\n",
        "#     master_columns = dataframes[0].columns\n",
        "#     aligned_data = [df.reindex(master_index).values for df in dataframes]\n",
        "#     data_array = np.stack(aligned_data, axis=0).transpose(1, 2, 0)\n",
        "#     print(\"資料堆疊完成。 陣列維度 (列數, 欄數, 檔案數):\", data_array.shape)\n",
        "\n",
        "#     # --- 步驟 3: 計算平均值 (加權或簡單) 與中位數 ---\n",
        "\n",
        "#     # 計算平均值\n",
        "#     if weights is not None:\n",
        "#         print(\"正在計算加權平均值...\")\n",
        "#         # 使用 np.average 進行加權計算\n",
        "#         mean_data = np.average(data_array, axis=2, weights=weights)\n",
        "#         mean_output_filename = 'ensemble_weighted_mean.csv'\n",
        "#     else:\n",
        "#         print(\"正在計算簡單平均值...\")\n",
        "#         mean_data = np.mean(data_array, axis=2)\n",
        "#         mean_output_filename = 'ensemble_mean.csv'\n",
        "\n",
        "#     # 計算中位數 (中位數沒有加權的概念，維持原樣)\n",
        "#     print(\"正在計算中位數...\")\n",
        "#     median_data = np.median(data_array, axis=2)\n",
        "\n",
        "#     # --- 步驟 4: 建立結果 DataFrame 並儲存為 CSV 檔案 ---\n",
        "#     # 平均值結果\n",
        "#     df_mean = pd.DataFrame(mean_data, index=master_index, columns=master_columns)\n",
        "#     mean_output_path = os.path.join(output_dir, 'submission.csv')\n",
        "#     df_mean.to_csv(mean_output_path)\n",
        "#     print(f\"平均值整合結果已儲存至: {mean_output_path}\")\n",
        "\n",
        "#     # # 中位數結果\n",
        "#     # df_median = pd.DataFrame(median_data, index=master_index, columns=master_columns)\n",
        "#     # median_output_path = os.path.join(output_dir, 'ensemble_median.csv')\n",
        "#     # df_median.to_csv(median_output_path)\n",
        "#     # print(f\"中位數整合結果已儲存至: {median_output_path}\")\n",
        "\n",
        "# # 2. 定義您所有 submission.csv 檔案的路徑列表。\n",
        "# #    請將下面的列表換成您自己的檔案路徑。\n",
        "# submission_files = [\n",
        "#     \"/kaggle/input/caformrt-28-8/submission.csv\",\n",
        "#     \"/kaggle/input/convnext0small-33-2/submission.csv\",\n",
        "#   #\"/kaggle/input/convnext-base-29-6/submission.csv\"\n",
        "# ]\n",
        "\n",
        "# file_weights = [0.8, 0.2]\n",
        "# # 3. 執行整合函式。\n",
        "# ensemble_submissions(submission_files, weights=file_weights)\n",
        "# #simple average\n",
        "# #ensemble_submissions(submission_files)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AU7BTtbQH8Oq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8af61f88",
        "outputId": "4e69820d-99f3-47cb-bcee-f03618ad4b3b"
      },
      "source": [
        "import os\n",
        "\n",
        "# Check the files in the specified directory\n",
        "directory_path = '/kaggle/input/caformrt-28-8/'\n",
        "if os.path.exists(directory_path):\n",
        "    print(f\"Files in {directory_path}:\")\n",
        "    for filename in os.listdir(directory_path):\n",
        "        print(filename)\n",
        "else:\n",
        "    print(f\"Directory not found: {directory_path}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory not found: /kaggle/input/caformrt-28-8/\n"
          ]
        }
      ]
    }
  ]
}